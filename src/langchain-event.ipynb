{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-33e4f353cb26464ba7efeffb815d81be\n",
      "https://api.deepseek.com\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "os.environ[\"DEEPSEEK_API_URL\"] = os.getenv(\"DEEPSEEK_API_URL\")\n",
    "\n",
    "print(os.environ[\"DEEPSEEK_API_KEY\"])\n",
    "print(os.environ[\"DEEPSEEK_API_URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 6, 'total_tokens': 43, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 6}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'id': 'c29b2185-09f3-4a31-8200-0c248ebdd356', 'finish_reason': 'stop', 'logprobs': None}, id='run-7e2ea37d-347c-4580-b117-12807abb3b81-0', usage_metadata={'input_tokens': 6, 'output_tokens': 37, 'total_tokens': 43, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "  model = \"deepseek-chat\",\n",
    "  temperature = 0,\n",
    "  api_key = os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "  base_url = os.getenv(\"DEEPSEEK_API_URL\"),\n",
    ")\n",
    "\n",
    "llm.invoke(\"介绍下你自己\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain 是一个用于构建基于大型语言模型（LLMs）的应用程序的框架。它旨在帮助开发者更轻松地集成和使用大型语言模型（如 OpenAI 的 GPT 系列）来构建复杂的应用程序。LangChain 提供了一系列工具和模块，使得开发者能够更高效地处理语言模型相关的任务，如文本生成、问答、对话系统等。\\n\\n### 主要功能\\n1. **链式调用（Chains）**：允许开发者将多个语言模型调用或其他操作串联起来，形成一个复杂的处理流程。\\n2. **记忆（Memory）**：支持在对话或任务中保持上下文记忆，使得模型能够记住之前的交互信息。\\n3. **代理（Agents）**：允许模型根据输入动态选择和执行不同的工具或操作，类似于一个智能代理。\\n4. **数据加载（Data Loaders）**：提供工具来加载和处理各种数据源，如文本文件、数据库、API 等。\\n5. **提示模板（Prompt Templates）**：帮助开发者创建和管理提示（prompts），以便更好地引导语言模型生成所需的输出。\\n6. **集成（Integrations）**：支持与多种外部工具和服务的集成，如向量数据库、API 等。\\n\\n### 使用场景\\n- **问答系统**：构建基于文档的问答系统，能够从大量文本中提取信息并生成答案。\\n- **对话系统**：创建智能对话代理，能够进行多轮对话并保持上下文。\\n- **文本生成**：生成高质量的文本内容，如文章、报告、代码等。\\n- **自动化任务**：通过代理和链式调用，自动化处理复杂的任务流程。\\n\\n### 示例代码\\n以下是一个简单的 LangChain 示例，展示如何使用 OpenAI 的 GPT 模型生成文本：\\n\\n```python\\nfrom langchain import OpenAI, PromptTemplate, LLMChain\\n\\n# 初始化 OpenAI 模型\\nllm = OpenAI(api_key=\"your_openai_api_key\")\\n\\n# 定义提示模板\\ntemplate = \"请生成一段关于{topic}的简短描述。\"\\nprompt = PromptTemplate(template=template, input_variables=[\"topic\"])\\n\\n# 创建链式调用\\nchain = LLMChain(llm=llm, prompt=prompt)\\n\\n# 运行链式调用\\noutput = chain.run(topic=\"人工智能\")\\nprint(output)\\n```\\n\\n### 总结\\nLangChain 是一个强大的工具，能够帮助开发者更高效地利用大型语言模型构建复杂的应用程序。通过其丰富的功能和模块，开发者可以轻松实现各种语言模型相关的任务，并集成到现有的系统中。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 527, 'prompt_tokens': 7, 'total_tokens': 534, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 7}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'id': '7faa81e2-a788-4332-ac49-2fd72f159826', 'finish_reason': 'stop', 'logprobs': None}, id='run-900423ae-09b4-4ffa-a395-45ffa069d536-0', usage_metadata={'input_tokens': 7, 'output_tokens': 527, 'total_tokens': 534, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "  model = \"deepseek-chat\",\n",
    "  temperature = 0,\n",
    "  api_key = os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "  base_url = os.getenv(\"DEEPSEEK_API_URL\"),\n",
    ")\n",
    "question = \"langchain是什么？\"\n",
    "\n",
    "# invoke 事件\n",
    "llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
